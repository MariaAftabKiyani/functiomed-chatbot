# ============================================================================
# FunctiOMed Chatbot API - Environment Configuration
# ============================================================================
# Copy this file to .env and update the values as needed

# ============================================================================
# Application Settings
# ============================================================================
APP_NAME="FunctiOMed Chatbot API"
APP_VERSION="1.0.0"
DEBUG=False

# CORS Settings (comma-separated origins or "*" for all)
ALLOWED_ORIGINS=*

# ============================================================================
# Qdrant Vector Database
# ============================================================================
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=
QDRANT_COLLECTION=functiomed_medical_docs
QDRANT_VECTOR_SIZE=1024
QDRANT_DISTANCE_METRIC=Cosine
QDRANT_TIMEOUT=30

# ============================================================================
# Embedding Model (BGE-M3)
# ============================================================================
EMBEDDING_MODEL=BAAI/bge-m3
EMBEDDING_DEVICE=cuda
EMBEDDING_BATCH_SIZE=16
EMBEDDING_MAX_LENGTH=8192
EMBEDDING_NORMALIZE=True
EMBEDDING_USE_FP16=True

# ============================================================================
# HuggingFace Settings
# ============================================================================
# Required for downloading models (especially Llama models)
HF_HUB_TOKEN=your-hf-token-here
HF_API_TOKEN=your-hf-token-here
HF_HOME=./models/huggingface

# ============================================================================
# Document Processing
# ============================================================================
CHUNK_SIZE=800
CHUNK_OVERLAP=200
MIN_CHUNK_SIZE=200

# Retry Settings
MAX_RETRIES=3
RETRY_DELAY=1.0
UPLOAD_BATCH_SIZE=100

# ============================================================================
# Retrieval Settings
# ============================================================================
RETRIEVAL_TOP_K=3
RETRIEVAL_MIN_SCORE=0.5
RETRIEVAL_MAX_QUERY_LENGTH=512

# ============================================================================
# Cross-Encoder Re-ranking Settings
# ============================================================================
RERANKER_ENABLED=true
RERANKER_MODEL=BAAI/bge-reranker-v2-m3
RERANKER_TOP_K=3
RERANKER_BATCH_SIZE=16
RERANKER_DEVICE=cuda
RERANKER_USE_FP16=True

# ============================================================================
# Hybrid Search Settings (BM25 + Semantic)
# ============================================================================
HYBRID_SEARCH_ENABLED=true
HYBRID_ALPHA=0.7
BM25_K1=1.5
BM25_B=0.75

# ============================================================================
# LLM Configuration (GPU-accelerated with Quantization)
# ============================================================================

# Model Selection
LLM_MODEL_NAME=meta-llama/Llama-3.1-8B-Instruct

# Device Configuration
LLM_DEVICE=cuda

# Quantization Settings
# Options: int8 (recommended), int4 (max memory savings), fp16 (max quality), none
LLM_USE_QUANTIZATION=True
LLM_QUANTIZATION_TYPE=int8
LLM_USE_DOUBLE_QUANT=True

# Compute Settings
# Options: float16 (recommended for GPU), bfloat16, float32
LLM_COMPUTE_DTYPE=float16

# Memory Optimization
LLM_LOW_CPU_MEM_USAGE=True
# Options: auto (recommended), balanced, sequential
LLM_DEVICE_MAP=auto

# Generation Settings
LLM_MAX_TOKENS=300
LLM_TEMPERATURE=0.4
LLM_TOP_P=0.9
LLM_CONTEXT_WINDOW=2048

# ============================================================================
# RAG (Retrieval-Augmented Generation) Configuration
# ============================================================================

# Context Settings
RAG_MAX_CONTEXT_TOKENS=2048
RAG_MAX_CHUNKS=10
RAG_MIN_CHUNK_SCORE=0.3

# Response Settings
RAG_ENABLE_CITATIONS=true

# Fallback Responses (when no relevant information found)
RAG_FALLBACK_RESPONSE_DE="Entschuldigung, ich habe keine relevanten Informationen zu Ihrer Frage. Für weitere Unterstützung können Sie uns gerne kontaktieren:\n\n**Telefon**: +41 (0)44 401 15 15\n**Email**: functiomed@hin.ch\n\nWir antworten in der Regel innerhalb von 24 Stunden an Werktagen."

RAG_FALLBACK_RESPONSE_EN="I apologize, but I don't have relevant information available regarding this. For further assistance, you can contact us:\n\n**Phone**: +41 (0)44 401 15 15\n**Email**: functiomed@hin.ch\n\nWe usually respond to inquiries within 24 hours on weekdays."

RAG_FALLBACK_RESPONSE_FR="Je m'excuse, mais je n'ai pas d'informations pertinentes disponibles à ce sujet. Pour une assistance supplémentaire, vous pouvez nous contacter :\n\n**Téléphone** : +41 (0)44 401 15 15\n**Email** : functiomed@hin.ch\n\nNous répondons généralement aux demandes dans les 24 heures les jours ouvrables."

# ============================================================================
# TTS Configuration (Text-to-Speech via HuggingFace API)
# ============================================================================
TTS_CACHE_DIR=./data/tts_cache
TTS_MAX_CHARS=2000
TTS_TIMEOUT=30


